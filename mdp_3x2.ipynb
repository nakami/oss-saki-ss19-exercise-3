{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dQGN1cYygE7p"
   },
   "source": [
    "# 3x2 warehouse layout\n",
    "\n",
    "## training data and layout\n",
    "\n",
    "I obtained the distribution of actions from `warehousetraining3x2.txt` (see jupyter notebook `overview.ipynb` for that):       \n",
    "\n",
    "```\n",
    "store white      0.1278\n",
    "store blue       0.1253\n",
    "store red        0.2469\n",
    "restore white    0.1278\n",
    "restore blue     0.1253\n",
    "restore red      0.2469\n",
    "```\n",
    "\n",
    "For the 3x2 warehouse I choose the following storage layout:\n",
    "\n",
    "```\n",
    "0 1 2\n",
    "3 4 5\n",
    "```\n",
    "\n",
    "The robot arm starts from field 0 (x=0,y=0) which already counts as a distance of 1. Storing or restoring in 1 or 3 costs a distance of 2, in 2 and 4 it costs 3. Traveling to 5 has a distance of 4:\n",
    "\n",
    "```\n",
    "1 2 3\n",
    "2 3 4\n",
    "```\n",
    "\n",
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cm9HcXaMgE7q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "data_dir_3x2 = 'data_3x2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ca6cq8KWgE7u"
   },
   "outputs": [],
   "source": [
    "distance_array = [1, 2, 3, 2, 3, 4]\n",
    "reward_array = [4, 3, 2, 3, 2, 1]\n",
    "\n",
    "# do next action on position...\n",
    "action_positions = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "field_map = {\n",
    "    0: 'none',\n",
    "    1: 'white',\n",
    "    2: 'blue',\n",
    "    3: 'red'\n",
    "}\n",
    "\n",
    "field_map_inverse = {v: k for k, v in field_map.items()}\n",
    "\n",
    "action_map = {\n",
    "    0: ('store', 'white'),\n",
    "    1: ('store', 'blue'),\n",
    "    2: ('store', 'red'),\n",
    "    3: ('restore', 'white'),\n",
    "    4: ('restore', 'blue'),\n",
    "    5: ('restore', 'red')\n",
    "}\n",
    "\n",
    "action_map_inverse = {v: k for k, v in action_map.items()}\n",
    "\n",
    "training_action_dist = {\n",
    "    0: 0.1278, # store   white\n",
    "    1: 0.1253, # store   blue\n",
    "    2: 0.2469, # store   red\n",
    "    3: 0.1278, # restore white\n",
    "    4: 0.1253, # restore blue\n",
    "    5: 0.2469  # restore red\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUXvlyVlgE7x"
   },
   "outputs": [],
   "source": [
    "def generate_statelist() -> List[Tuple[int]]:\n",
    "    # 0...3 := none, white, blue, red\n",
    "    state_per_field = [0, 1, 2, 3]\n",
    "    # 0...5 := store {white, blue, red}, restore {white, blue, red}\n",
    "    actions = [0, 1, 2, 3, 4, 5]\n",
    "    #storage_states = [p for p in itertools.product(storage_state, repeat=4)]\n",
    "    statelist = []\n",
    "    for action in actions:\n",
    "        for x0 in state_per_field:\n",
    "            for x1 in state_per_field:\n",
    "                for x2 in state_per_field:\n",
    "                    for x3 in state_per_field:\n",
    "                        for x4 in state_per_field:\n",
    "                            for x5 in state_per_field:\n",
    "                                state = (x0, x1, x2, x3, x4, x5, action)\n",
    "                                statelist.append(state)\n",
    "    print(f'generated {len(statelist)} states')\n",
    "    return statelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uYFGAD7tgE70",
    "outputId": "6993a5ba-f8b3-4e14-b630-626c75355fed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated 24576 states\n"
     ]
    }
   ],
   "source": [
    "statelist = generate_statelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKxiVdbkgE75"
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "# For a given state: get action\n",
    "def get_state_action(state_tup: Tuple[int], humanreadable: bool=False) -> Union[str, int]:\n",
    "    # last element in state tuple is the action\n",
    "    action = state_tup[-1]\n",
    "    if humanreadable:\n",
    "        return action_map[action]\n",
    "    else:\n",
    "        return action\n",
    "\n",
    "# For a given state: list of indizes of empty slots\n",
    "def get_state_free_slots(state_tup: Tuple[int]) -> List[int]:\n",
    "    return [index for index, slot in enumerate(state_tup[:-1]) if slot == 0]\n",
    "\n",
    "# For a given state: does it have empty slots?\n",
    "def state_has_any_free_slots(state_tup: Tuple[int]) -> bool:\n",
    "    return len(get_state_free_slots(state_tup)) > 0\n",
    "\n",
    "# For a given state: all slots free?\n",
    "def state_has_only_free_slots(state_tup: Tuple[int]) -> bool:\n",
    "    return len([index for index, slot in enumerate(state_tup[:-1]) if slot == 0]) == len(state_tup[:-1])\n",
    "\n",
    "# For a given state: list of indizes of certain color slots\n",
    "def get_state_slots_of_color(state_tup: Tuple[int], color_to_find: Union[int, str]) -> List[int]:\n",
    "    if isinstance(color_to_find, str):\n",
    "        color_int = field_map_inverse[color_to_find]\n",
    "    else:\n",
    "        color_int = color_to_find\n",
    "    return [index for index, slot in enumerate(state_tup[:-1]) if slot == color_int]\n",
    "\n",
    "# For a given state: does it have certain color slots?\n",
    "def state_has_any_slots_of_color(state_tup: Tuple[int], color_to_find: Union[int, str]) -> bool:\n",
    "    return len(get_state_slots_of_color(state_tup, color_to_find)) > 0\n",
    "\n",
    "# For two given states: list of indizes of varying slots\n",
    "def get_states_varying_slots(state_tup0: Tuple[int], state_tup1: Tuple[int]) -> List[int]:\n",
    "    state0_slots = state_tup0[:-1]\n",
    "    state1_slots = state_tup1[:-1]\n",
    "    indizes_varying_slots = []\n",
    "    for index, slot_content in enumerate(state0_slots):\n",
    "        if slot_content != state1_slots[index]:\n",
    "            indizes_varying_slots.append(index)\n",
    "    return indizes_varying_slots\n",
    "\n",
    "# For two given states: do they have varying slots?\n",
    "def states_have_varying_slots(state_tup0: Tuple[int], state_tup1: Tuple[int]) -> bool:\n",
    "    return len(get_states_varying_slots(state_tup0, state_tup1)) > 0\n",
    "\n",
    "\n",
    "# For two given states: is state1 a valid state after state0?\n",
    "def states_are_valid_successors(state_tup0: Tuple[int], state_tup1: Tuple[int], action_position: int) -> Tuple[bool, str]:\n",
    "    if state_tup0[action_position] == state_tup1[action_position]:\n",
    "        # nothing changed at action_position...\n",
    "        return False\n",
    "    # check rest if it is the same\n",
    "    for ind, field in enumerate(state_tup0[:-1]):\n",
    "        # skip field that is where action should take place\n",
    "        if ind == action_position:\n",
    "            continue\n",
    "        if field != state_tup1[ind]:\n",
    "            return False\n",
    "    # store\n",
    "    if state_tup0[-1] in [0, 1, 2]: # ['store white', 'store blue', 'store red']\n",
    "        if (state_tup0[-1] + 1) == state_tup1[action_position] and state_tup0[action_position] == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    # restore\n",
    "    if state_tup0[-1] in [3, 4, 5]: # ['restore white', 'restore blue', 'restore red']\n",
    "        if 0 == state_tup1[action_position] and state_tup1[action_position] == (state_tup0[-1] - 2):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    raise Exception(f'state_tup0: {state_tup0}, state_tup1: {state_tup1}')\n",
    "\n",
    "# call states_are_valid_successors beforehand!\n",
    "def distance_between_successor_states(state_tup0: Tuple[int], state_tup1: Tuple[int]) -> int:\n",
    "    #if not states_are_valid_successors(state_tup0, state_tup1):\n",
    "    #    raise Error('states_are_valid_successors returned False')\n",
    "    try:\n",
    "        changed_slot = get_states_varying_slots(state_tup0, state_tup1)[0]\n",
    "    except IndexError:\n",
    "        print(f'state_tup0: {state_tup0}, state_tup1: {state_tup1}')\n",
    "    return distance_array[changed_slot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7yZzma3wgE78",
    "outputId": "9042e6f5-596a-4651-852d-dcc00c6f84f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 3, 0, 2, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statelist[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "YQcR6Ty5gE7_",
    "outputId": "b8f31096-e59b-4c7f-8aaf-87eb8d815c5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state0:\t\t\t\t(0, 0, 0, 3, 0, 2, 0)\n",
      "get_state_action:\t\t('store', 'white')\n",
      "get_state_free_slots:\t\t[0, 1, 2, 4]\n",
      "state_has_any_free_slots:\tTrue\n",
      "state_has_only_free_slots:\tFalse\n",
      "get_state_slots_of_color:\t[5]\n",
      "get_state_slots_of_color:\t[5]\n",
      "state_has_any_slots_of_color:\tTrue\n",
      "\n",
      "state0:\t\t\t\t(0, 0, 0, 3, 0, 2, 0)\n",
      "action of state0:\t\t0\n",
      "action of state0:\t\t('store', 'white')\n",
      "statelist[51]:\t\t\t(1, 0, 0, 3, 0, 2, 0)\n",
      "get_states_varying_slots:\t[0]\n",
      "states_have_varying_slots:\tTrue\n",
      "states_are_valid_successors:\tTrue\n"
     ]
    }
   ],
   "source": [
    "# test helper functions\n",
    "# state0: (0, 0, 0, 3, 0, 2, 0)\n",
    "state0 = statelist[50]\n",
    "state1 = (1, 0, 0, 3, 0, 2, 0)\n",
    "\n",
    "print(f'state0:\\t\\t\\t\\t{state0}')\n",
    "print(f'get_state_action:\\t\\t{get_state_action(state0, humanreadable=True)}')\n",
    "print(f'get_state_free_slots:\\t\\t{get_state_free_slots(state0)}')\n",
    "print(f'state_has_any_free_slots:\\t{state_has_any_free_slots(state0)}')\n",
    "print(f'state_has_only_free_slots:\\t{state_has_only_free_slots(state0)}')\n",
    "print(f'get_state_slots_of_color:\\t{get_state_slots_of_color(state0, 2)}')\n",
    "print(f'get_state_slots_of_color:\\t{get_state_slots_of_color(state0, \"blue\")}')\n",
    "print(f'state_has_any_slots_of_color:\\t{state_has_any_slots_of_color(state0, \"blue\")}')\n",
    "print()\n",
    "print(f'state0:\\t\\t\\t\\t{state0}')\n",
    "print(f'action of state0:\\t\\t{get_state_action(state0)}')\n",
    "print(f'action of state0:\\t\\t{get_state_action(state0, humanreadable=True)}')\n",
    "print(f'statelist[51]:\\t\\t\\t{state1}')\n",
    "print(f'get_states_varying_slots:\\t{get_states_varying_slots(state0, state1)}')\n",
    "print(f'states_have_varying_slots:\\t{states_have_varying_slots(state0, state1)}')\n",
    "print(f'states_are_valid_successors:\\t{states_are_valid_successors(state0, state1, 0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SIwUOJjhgE8D"
   },
   "outputs": [],
   "source": [
    "def fix_tpm_empty_row(tpm):\n",
    "    for index, row_vector in enumerate(tpm):\n",
    "        sum_ = np.sum(row_vector)\n",
    "        if sum_ == 0.0:\n",
    "            # it should stay in the state then since the sum of each row has to equal one\n",
    "            tpm[index, index] = 1.0\n",
    "            continue\n",
    "    return tpm\n",
    "\n",
    "def create_tpms(statelist):\n",
    "    tpms = []\n",
    "    inner_counter = 0\n",
    "    for idx, action_position in enumerate(action_positions):\n",
    "        print(f'{idx + 1} / {len(action_positions)} tpms... ', end='')\n",
    "        tpm = np.zeros((len(statelist), len(statelist)), dtype=np.float16)\n",
    "        for x, state0 in enumerate(statelist):\n",
    "            for y, state1 in enumerate(statelist):\n",
    "                valid_succ = states_are_valid_successors(state0, state1, action_position)\n",
    "                if valid_succ:\n",
    "                    inner_counter += 1\n",
    "                    action = get_state_action(state1)\n",
    "                    tpm[x, y] = training_action_dist[action]\n",
    "                    if inner_counter == 5:\n",
    "                        inner_counter = 0\n",
    "                        continue\n",
    "        fix_tpm_empty_row(tpm)\n",
    "        tpms.append(tpm)\n",
    "        print('ok')\n",
    "    return tpms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DIhKbyiWgE8F"
   },
   "outputs": [],
   "source": [
    "def generate_reward_matrix(statelist):\n",
    "    rm = np.zeros((len(statelist), len(action_positions)), dtype=np.float16)\n",
    "    for idx, action_position in enumerate(action_positions):\n",
    "        print(f'{idx + 1} / {len(action_positions)} rm columns... ', end='')\n",
    "        for ind0, state0 in enumerate(statelist):\n",
    "            for ind1, state1 in enumerate(statelist):\n",
    "                if state1 == state0:\n",
    "                    continue\n",
    "                valid_succ = states_are_valid_successors(state0, state1, action_position)\n",
    "                if valid_succ:\n",
    "                    rm[ind0, action_position] = reward_array[distance_between_successor_states(state0, state1)-1]\n",
    "        for ind0, state0 in enumerate(statelist):\n",
    "            # punish store when non-empty\n",
    "            if get_state_action(state0) in [0, 1, 2] and state0[action_position] != 0:\n",
    "                rm[ind0, action_position] = -100\n",
    "                continue\n",
    "            # punish restore when empty\n",
    "            if get_state_action(state0) == 3 and state0[action_position] != 1:\n",
    "                rm[ind0, action_position] = -100\n",
    "                continue\n",
    "            elif get_state_action(state0) == 4 and state0[action_position] != 2:\n",
    "                rm[ind0, action_position] = -100\n",
    "                continue\n",
    "            elif get_state_action(state0) == 5 and state0[action_position] != 3:\n",
    "                rm[ind0, action_position] = -100\n",
    "                continue\n",
    "        print('ok')\n",
    "    return rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "w2mDSSYGgE8J",
    "outputId": "653e796c-d0e7-486c-e615-b838e8192ea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated 24576 states\n",
      "1 / 6 tpms... ok\n",
      "2 / 6 tpms... ok\n",
      "3 / 6 tpms... ok\n",
      "4 / 6 tpms... ok\n",
      "5 / 6 tpms... ok\n",
      "6 / 6 tpms... ok\n",
      "1 / 6 rm columns... ok\n",
      "2 / 6 rm columns... ok\n",
      "3 / 6 rm columns... ok\n",
      "4 / 6 rm columns... ok\n",
      "5 / 6 rm columns... ok\n",
      "6 / 6 rm columns... ok\n"
     ]
    }
   ],
   "source": [
    "import mdptoolbox\n",
    "\n",
    "states = generate_statelist()\n",
    "tpms = create_tpms(statelist)\n",
    "rm = generate_reward_matrix(statelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FSIpcFqngE8N"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(f'{data_dir_3x2}/.~tpms_list.npy', tpms)\n",
    "#tpms = np.load(f'{data_dir_3x2}/.~tpms_list.npy')\n",
    "np.save(f'{data_dir_3x2}/.~rm.npy', rm)\n",
    "#rm = np.load(f'{data_dir_3x2}/.~rm.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8QuYv-L-gE8P",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mdptoolbox\n",
    "mdp_result_policy = mdptoolbox.mdp.PolicyIteration(tpms, rm, 0.999, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k6q8TE1ogE8S"
   },
   "outputs": [],
   "source": [
    "import mdptoolbox\n",
    "mdp_result_value = mdptoolbox.mdp.ValueIteration(tpms, rm, 0.95, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "86ADXLQ9gE8U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolicyIteration: done\n"
     ]
    }
   ],
   "source": [
    "mdp_result_policy.run()\n",
    "print('PolicyIteration: done')\n",
    "#print(mdp_result_policy.policy)\n",
    "#print(mdp_result_policy.V)\n",
    "#print(mdp_result_policy.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cFBparX6gE8X",
    "outputId": "1ef01d8b-ef92-4cdc-d21f-b2c9cd1786e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueIteration: done\n"
     ]
    }
   ],
   "source": [
    "mdp_result_value.run()\n",
    "print('ValueIteration: done')\n",
    "#print(mdp_result_value.policy)\n",
    "#print(mdp_result_value.V)\n",
    "#print(mdp_result_value.iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eqRp_faBgE8b"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "For the 3x2 storage layout, both MDP solution (PolicyIteration: discount=0.999, ValueIteration: discount=0.95) perform worse for the training data set, but outperform the greedy algo when running on the order data set\n",
    "\n",
    "### Greedy\n",
    "\n",
    "The greedy implementation walks 26144 steps on the training set and 130 on the order set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ORR-qB3ZgE8c",
    "outputId": "35137979-b4eb-4494-ae04-ecd739cf5e56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy_algo.distance_walked:\t26144\n",
      "greedy_algo.distance_walked:\t130\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from GreedyAlgo import GreedyAlgo\n",
    "\n",
    "data_dir_3x2 = 'data_3x2'\n",
    "file_train_3x2 = 'warehousetraining3x2.txt'\n",
    "file_order_3x2 = 'warehouseorder3x2.txt'\n",
    "csv_data_file_train = f'{data_dir_3x2}\\\\{file_train_3x2}'\n",
    "csv_data_file_order = f'{data_dir_3x2}\\\\{file_order_3x2}'\n",
    "\n",
    "df_3x2_train = pd.read_csv(csv_data_file_train, sep='\\t', header=None, names=[\"operation_type\", \"color\"])\n",
    "df_3x2_order = pd.read_csv(csv_data_file_order, sep='\\t', header=None, names=[\"operation_type\", \"color\"])\n",
    "\n",
    "actions_3x2_train = list(df_3x2_train.itertuples(index=False))\n",
    "actions_3x2_order = list(df_3x2_order.itertuples(index=False))\n",
    "\n",
    "greedy_algo = GreedyAlgo(6)\n",
    "for action in actions_3x2_train:\n",
    "    greedy_algo.run_next_action(action)\n",
    "print(f'greedy_algo.distance_walked:\\t{greedy_algo.distance_walked}')\n",
    "\n",
    "greedy_algo = GreedyAlgo(6)\n",
    "for action in actions_3x2_order:\n",
    "    greedy_algo.run_next_action(action)\n",
    "print(f'greedy_algo.distance_walked:\\t{greedy_algo.distance_walked}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PolicyIteration\n",
    "\n",
    "The policy from PolicyIteration walks 26456 steps on the training set and 126 on the order set (discount=0.999). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q7GYdA-fgE8j",
    "outputId": "96024fc9-01fb-42d9-df94-ebef0b486165"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai_algo.distance_walked:\t26456\n",
      "ai_algo.distance_walked:\t126\n"
     ]
    }
   ],
   "source": [
    "# mdp_result_policy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from AIAlgo import AIAlgo\n",
    "\n",
    "ai_algo = AIAlgo(mdp_result_policy.policy, statelist, 6)\n",
    "for action in actions_3x2_train:\n",
    "    ai_algo.run_next_action(action)\n",
    "print(f'ai_algo.distance_walked:\\t{ai_algo.distance_walked}')\n",
    "\n",
    "ai_algo = AIAlgo(mdp_result_policy.policy, statelist, 6)\n",
    "for action in actions_3x2_order:\n",
    "    ai_algo.run_next_action(action)\n",
    "print(f'ai_algo.distance_walked:\\t{ai_algo.distance_walked}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ValueIteration\n",
    "\n",
    "The policy from ValueIteration walks 26422 steps on the training set and 126 on the order set (discount=0.95)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNDhgzdigE8n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai_algo.distance_walked:\t26422\n",
      "ai_algo.distance_walked:\t126\n"
     ]
    }
   ],
   "source": [
    "# mdp_result_value\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from AIAlgo import AIAlgo\n",
    "\n",
    "ai_algo = AIAlgo(mdp_result_value.policy, statelist, 6)\n",
    "for action in actions_3x2_train:\n",
    "    ai_algo.run_next_action(action)\n",
    "print(f'ai_algo.distance_walked:\\t{ai_algo.distance_walked}')\n",
    "\n",
    "ai_algo = AIAlgo(mdp_result_value.policy, statelist, 6)\n",
    "for action in actions_3x2_order:\n",
    "    ai_algo.run_next_action(action)\n",
    "print(f'ai_algo.distance_walked:\\t{ai_algo.distance_walked}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "mdp_3x2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
